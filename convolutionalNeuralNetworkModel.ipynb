{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import deeplake\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mfcc_length(mfcc_list, target_length=100):\n",
    "    \"\"\"Standardize MFCC matrices to a fixed length\"\"\"\n",
    "    result = []\n",
    "    for mfcc in mfcc_list:\n",
    "        current_length = mfcc.shape[1]\n",
    "        if current_length > target_length:\n",
    "            # Truncate if longer than target\n",
    "            standardized = mfcc[:, :target_length]\n",
    "        else:\n",
    "            # Pad with zeros if shorter\n",
    "            padding = np.zeros((mfcc.shape[0], target_length - current_length))\n",
    "            standardized = np.hstack([mfcc, padding])\n",
    "        \n",
    "        # Flatten the matrix for traditional ML models\n",
    "        result.append(standardized.flatten())\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABELS = {\"stop\", \"go\", \"up\", \"down\", \"forward\", \"backward\"}\n",
    "\n",
    "def extract_filtered_mfcc_features(dataset, n_mfcc=13, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features only for the selected words.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: The Deeplake dataset containing audio tensors.\n",
    "    - n_mfcc: Number of MFCC coefficients to extract.\n",
    "    - sample_rate: Target sample rate for librosa processing.\n",
    "    \n",
    "    Returns:\n",
    "    - X: NumPy array of MFCC features (num_samples, n_mfcc)\n",
    "    - y: NumPy array of corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        point_label = dataset.labels[i].data()['text'][0]  \n",
    "\n",
    "        if point_label in TARGET_LABELS:  # Keep only target samples\n",
    "            \n",
    "            audio = dataset['audios'][i].numpy().squeeze()  # Extract audio data\n",
    "            \n",
    "            # Compute MFCC\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "            # mfcc_mean = np.mean(mfcc, axis=1)  # second method: Can take mean of factors for more simplistic feature set\n",
    "            \n",
    "            X.append(mfcc)\n",
    "            y.append(point_label)\n",
    "            \n",
    "    return standardize_mfcc_length(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/speech-commands-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/speech-commands-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\deeplake\\core\\tensor.py:719: UserWarning: Indexing by integer in a for loop, like `for i in range(len(ds)): ... ds.tensor[i]` can be quite slow. Use `for i, sample in enumerate(ds)` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = deeplake.load('hub://activeloop/speech-commands-train')\n",
    "\n",
    "# Extract features\n",
    "X, y = extract_filtered_mfcc_features(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down': 0, 'go': 1, 'stop': 2, 'up': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Balance dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# Encode labels so they are ints instead of strings for training the model\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert string labels to integers\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)  # Use the same encoder to transform test labels\n",
    "\n",
    "# Check class mapping\n",
    "print(dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))\n",
    "\n",
    "\n",
    "# Get amount of labels for output layer of neural network (how many classes we are distinguishing)\n",
    "unique_labels = np.unique(y_train)  \n",
    "highest_label = np.max(unique_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Referenced:  https://www.tensorflow.org/tutorials/images/cnn\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(1300, 1)))\n",
    "# model.add(layers.MaxPooling1D(pool_size=2))\n",
    "# model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(pool_size=2))\n",
    "# model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layers on top\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(highest_label + 1))\n",
    "# model.add(layers.Dense(highest_label + 1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 63ms/step - accuracy: 0.5955 - loss: 1.0197 - val_accuracy: 0.7710 - val_loss: 0.6374\n",
      "Epoch 2/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - accuracy: 0.7834 - loss: 0.5823 - val_accuracy: 0.8078 - val_loss: 0.5237\n",
      "Epoch 3/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - accuracy: 0.8605 - loss: 0.4005 - val_accuracy: 0.8277 - val_loss: 0.4584\n",
      "Epoch 4/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.8960 - loss: 0.3186 - val_accuracy: 0.8487 - val_loss: 0.4242\n",
      "Epoch 5/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 0.9257 - loss: 0.2285 - val_accuracy: 0.8482 - val_loss: 0.4274\n",
      "Epoch 6/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 0.9416 - loss: 0.1767 - val_accuracy: 0.8382 - val_loss: 0.4555\n",
      "Epoch 7/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - accuracy: 0.9638 - loss: 0.1231 - val_accuracy: 0.8403 - val_loss: 0.4725\n",
      "Epoch 8/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9669 - loss: 0.1039 - val_accuracy: 0.8498 - val_loss: 0.4717\n",
      "Epoch 9/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 0.9780 - loss: 0.0846 - val_accuracy: 0.8550 - val_loss: 0.4947\n",
      "Epoch 10/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 0.9854 - loss: 0.0583 - val_accuracy: 0.8493 - val_loss: 0.5108\n",
      "Epoch 11/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 58ms/step - accuracy: 0.9876 - loss: 0.0430 - val_accuracy: 0.8587 - val_loss: 0.5217\n",
      "Epoch 12/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9949 - loss: 0.0272 - val_accuracy: 0.8566 - val_loss: 0.5835\n",
      "Epoch 13/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 62ms/step - accuracy: 0.9960 - loss: 0.0208 - val_accuracy: 0.8603 - val_loss: 0.5927\n",
      "Epoch 14/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9968 - loss: 0.0207 - val_accuracy: 0.8524 - val_loss: 0.5913\n",
      "Epoch 15/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 0.9881 - loss: 0.0376 - val_accuracy: 0.8482 - val_loss: 0.6514\n",
      "Epoch 16/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - accuracy: 0.9831 - loss: 0.0509 - val_accuracy: 0.8519 - val_loss: 0.6258\n",
      "Epoch 17/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 0.9970 - loss: 0.0182 - val_accuracy: 0.8529 - val_loss: 0.6364\n",
      "Epoch 18/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 65ms/step - accuracy: 0.9995 - loss: 0.0083 - val_accuracy: 0.8582 - val_loss: 0.6393\n",
      "Epoch 19/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.9992 - loss: 0.0062 - val_accuracy: 0.8655 - val_loss: 0.6511\n",
      "Epoch 20/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8640 - val_loss: 0.6701\n",
      "Epoch 21/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8619 - val_loss: 0.6850\n",
      "Epoch 22/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8603 - val_loss: 0.7024\n",
      "Epoch 23/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8613 - val_loss: 0.7128\n",
      "Epoch 24/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8624 - val_loss: 0.7354\n",
      "Epoch 25/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.8033e-04 - val_accuracy: 0.8629 - val_loss: 0.7488\n",
      "Epoch 26/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.0627e-04 - val_accuracy: 0.8645 - val_loss: 0.7558\n",
      "Epoch 27/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.7034e-04 - val_accuracy: 0.8645 - val_loss: 0.7820\n",
      "Epoch 28/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 4.8582e-04 - val_accuracy: 0.8640 - val_loss: 0.7849\n",
      "Epoch 29/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.1369e-04 - val_accuracy: 0.8582 - val_loss: 0.7968\n",
      "Epoch 30/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 3.6186e-04 - val_accuracy: 0.8608 - val_loss: 0.8184\n",
      "Epoch 31/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.8361e-04 - val_accuracy: 0.8608 - val_loss: 0.8224\n",
      "Epoch 32/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.6756e-04 - val_accuracy: 0.8613 - val_loss: 0.8472\n",
      "Epoch 33/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.3160e-04 - val_accuracy: 0.8608 - val_loss: 0.8524\n",
      "Epoch 34/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.9558e-04 - val_accuracy: 0.8592 - val_loss: 0.8687\n",
      "Epoch 35/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.4780e-04 - val_accuracy: 0.8624 - val_loss: 0.8798\n",
      "Epoch 36/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.3921e-04 - val_accuracy: 0.8613 - val_loss: 0.8930\n",
      "Epoch 37/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.3050e-04 - val_accuracy: 0.8603 - val_loss: 0.9047\n",
      "Epoch 38/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.1612e-04 - val_accuracy: 0.8613 - val_loss: 0.9266\n",
      "Epoch 39/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.5666e-05 - val_accuracy: 0.8592 - val_loss: 0.9338\n",
      "Epoch 40/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.4789e-05 - val_accuracy: 0.8587 - val_loss: 0.9492\n",
      "Epoch 41/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 7.4417e-05 - val_accuracy: 0.8592 - val_loss: 0.9589\n",
      "Epoch 42/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 6.3172e-05 - val_accuracy: 0.8577 - val_loss: 0.9732\n",
      "Epoch 43/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.0014e-05 - val_accuracy: 0.8613 - val_loss: 0.9912\n",
      "Epoch 44/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.8116e-05 - val_accuracy: 0.8624 - val_loss: 1.0053\n",
      "Epoch 45/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.1308e-05 - val_accuracy: 0.8592 - val_loss: 1.0188\n",
      "Epoch 46/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 3.6939e-05 - val_accuracy: 0.8603 - val_loss: 1.0344\n",
      "Epoch 47/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.0323e-05 - val_accuracy: 0.8598 - val_loss: 1.0384\n",
      "Epoch 48/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.6533e-05 - val_accuracy: 0.8603 - val_loss: 1.0558\n",
      "Epoch 49/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 2.3044e-05 - val_accuracy: 0.8598 - val_loss: 1.0642\n",
      "Epoch 50/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.9458e-05 - val_accuracy: 0.8619 - val_loss: 1.0810\n",
      "Epoch 51/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.6847e-05 - val_accuracy: 0.8619 - val_loss: 1.0982\n",
      "Epoch 52/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.4712e-05 - val_accuracy: 0.8624 - val_loss: 1.1144\n",
      "Epoch 53/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.3125e-05 - val_accuracy: 0.8613 - val_loss: 1.1211\n",
      "Epoch 54/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.1147e-05 - val_accuracy: 0.8613 - val_loss: 1.1400\n",
      "Epoch 55/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 9.3747e-06 - val_accuracy: 0.8619 - val_loss: 1.1517\n",
      "Epoch 56/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.9507e-06 - val_accuracy: 0.8613 - val_loss: 1.1646\n",
      "Epoch 57/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 7.6709e-06 - val_accuracy: 0.8608 - val_loss: 1.1739\n",
      "Epoch 58/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.4785e-06 - val_accuracy: 0.8619 - val_loss: 1.1940\n",
      "Epoch 59/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.1189e-06 - val_accuracy: 0.8608 - val_loss: 1.2041\n",
      "Epoch 60/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.2177e-06 - val_accuracy: 0.8592 - val_loss: 1.2194\n",
      "Epoch 61/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.3349e-06 - val_accuracy: 0.8624 - val_loss: 1.2393\n",
      "Epoch 62/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.0591e-06 - val_accuracy: 0.8582 - val_loss: 1.2392\n",
      "Epoch 63/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.1817e-06 - val_accuracy: 0.8603 - val_loss: 1.2649\n",
      "Epoch 64/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.9537e-06 - val_accuracy: 0.8592 - val_loss: 1.2715\n",
      "Epoch 65/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.5209e-06 - val_accuracy: 0.8598 - val_loss: 1.2766\n",
      "Epoch 66/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.1580e-06 - val_accuracy: 0.8613 - val_loss: 1.2936\n",
      "Epoch 67/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.0426e-06 - val_accuracy: 0.8577 - val_loss: 1.3063\n",
      "Epoch 68/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.7115e-06 - val_accuracy: 0.8608 - val_loss: 1.3214\n",
      "Epoch 69/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.5717e-06 - val_accuracy: 0.8592 - val_loss: 1.3429\n",
      "Epoch 70/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.3186e-06 - val_accuracy: 0.8587 - val_loss: 1.3539\n",
      "Epoch 71/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.2501e-06 - val_accuracy: 0.8577 - val_loss: 1.3604\n",
      "Epoch 72/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.0574e-06 - val_accuracy: 0.8608 - val_loss: 1.3757\n",
      "Epoch 73/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 8.6498e-07 - val_accuracy: 0.8582 - val_loss: 1.3840\n",
      "Epoch 74/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.4507e-07 - val_accuracy: 0.8587 - val_loss: 1.3933\n",
      "Epoch 75/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.3568e-07 - val_accuracy: 0.8582 - val_loss: 1.4117\n",
      "Epoch 76/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 6.0564e-07 - val_accuracy: 0.8603 - val_loss: 1.4242\n",
      "Epoch 77/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 5.1535e-07 - val_accuracy: 0.8571 - val_loss: 1.4463\n",
      "Epoch 78/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.4565e-07 - val_accuracy: 0.8582 - val_loss: 1.4502\n",
      "Epoch 79/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.0084e-07 - val_accuracy: 0.8571 - val_loss: 1.4609\n",
      "Epoch 80/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 3.6099e-07 - val_accuracy: 0.8582 - val_loss: 1.4854\n",
      "Epoch 81/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 3.1761e-07 - val_accuracy: 0.8582 - val_loss: 1.4906\n",
      "Epoch 82/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 2.7795e-07 - val_accuracy: 0.8571 - val_loss: 1.5067\n",
      "Epoch 83/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 2.4159e-07 - val_accuracy: 0.8582 - val_loss: 1.5088\n",
      "Epoch 84/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.0594e-07 - val_accuracy: 0.8577 - val_loss: 1.5306\n",
      "Epoch 85/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 1.9603e-07 - val_accuracy: 0.8587 - val_loss: 1.5436\n",
      "Epoch 86/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.6747e-07 - val_accuracy: 0.8582 - val_loss: 1.5532\n",
      "Epoch 87/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.4991e-07 - val_accuracy: 0.8587 - val_loss: 1.5668\n",
      "Epoch 88/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 1.2983e-07 - val_accuracy: 0.8571 - val_loss: 1.5774\n",
      "Epoch 89/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.1158e-07 - val_accuracy: 0.8577 - val_loss: 1.5944\n",
      "Epoch 90/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 9.9963e-08 - val_accuracy: 0.8566 - val_loss: 1.6102\n",
      "Epoch 91/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 8.6507e-08 - val_accuracy: 0.8577 - val_loss: 1.6122\n",
      "Epoch 92/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.8025e-08 - val_accuracy: 0.8582 - val_loss: 1.6311\n",
      "Epoch 93/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.7095e-08 - val_accuracy: 0.8582 - val_loss: 1.6433\n",
      "Epoch 94/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 6.1273e-08 - val_accuracy: 0.8587 - val_loss: 1.6555\n",
      "Epoch 95/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.1758e-08 - val_accuracy: 0.8571 - val_loss: 1.6660\n",
      "Epoch 96/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.0194e-08 - val_accuracy: 0.8587 - val_loss: 1.6771\n",
      "Epoch 97/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.9919e-08 - val_accuracy: 0.8566 - val_loss: 1.6892\n",
      "Epoch 98/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.5521e-08 - val_accuracy: 0.8571 - val_loss: 1.7031\n",
      "Epoch 99/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3623e-08 - val_accuracy: 0.8571 - val_loss: 1.7093\n",
      "Epoch 100/100\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.0538e-08 - val_accuracy: 0.8577 - val_loss: 1.7188\n"
     ]
    }
   ],
   "source": [
    "#Compile and train model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - 9ms/step - accuracy: 0.8577 - loss: 1.7188\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       476\n",
      "           1       0.85      0.85      0.85       476\n",
      "           2       0.87      0.89      0.88       476\n",
      "           3       0.84      0.85      0.85       476\n",
      "\n",
      "    accuracy                           0.86      1904\n",
      "   macro avg       0.86      0.86      0.86      1904\n",
      "weighted avg       0.86      0.86      0.86      1904\n",
      "\n",
      "Accuracy: 0.8576680672268907\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Get model predictions (logits)\n",
    "y_pred_logits = model.predict(X_test)  # This will return raw logits\n",
    "\n",
    "# Convert logits to class labels (since from_logits=True)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute accuracy separately\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "d161be9a-3b35-4d3d-9d1d-a799bc34232f"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
