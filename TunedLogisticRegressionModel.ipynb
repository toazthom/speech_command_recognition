{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import deeplake\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mfcc_length(mfcc_list, target_length=100):\n",
    "    \"\"\"Standardize MFCC matrices to a fixed length\"\"\"\n",
    "    result = []\n",
    "    for mfcc in mfcc_list:\n",
    "        current_length = mfcc.shape[1]\n",
    "        if current_length > target_length:\n",
    "            # Truncate if longer than target\n",
    "            standardized = mfcc[:, :target_length]\n",
    "        else:\n",
    "            # Pad with zeros if shorter\n",
    "            padding = np.zeros((mfcc.shape[0], target_length - current_length))\n",
    "            standardized = np.hstack([mfcc, padding])\n",
    "        \n",
    "        # Flatten the matrix for traditional ML models\n",
    "        result.append(standardized.flatten())\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABELS = {\"stop\", \"go\", \"up\", \"down\", \"forward\", \"backward\"}\n",
    "\n",
    "def extract_filtered_mfcc_features(dataset, n_mfcc=13, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features only for the selected words.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: The Deeplake dataset containing audio tensors.\n",
    "    - n_mfcc: Number of MFCC coefficients to extract.\n",
    "    - sample_rate: Target sample rate for librosa processing.\n",
    "    \n",
    "    Returns:\n",
    "    - X: NumPy array of MFCC features (num_samples, n_mfcc)\n",
    "    - y: NumPy array of corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        point_label = dataset.labels[i].data()['text'][0]  \n",
    "\n",
    "        if point_label in TARGET_LABELS:  # Keep only target samples\n",
    "            \n",
    "            audio = dataset['audios'][i].numpy().squeeze()  # Extract audio data\n",
    "            \n",
    "            # Compute MFCC\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "            # mfcc_mean = np.mean(mfcc, axis=1)  # second method: Can take mean of factors for more simplistic feature set\n",
    "            \n",
    "            X.append(mfcc)\n",
    "            y.append(point_label)\n",
    "            \n",
    "    return standardize_mfcc_length(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/speech-commands-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/speech-commands-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "dataset = deeplake.load('hub://activeloop/speech-commands-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\deeplake\\core\\tensor.py:719: UserWarning: Indexing by integer in a for loop, like `for i in range(len(ds)): ... ds.tensor[i]` can be quite slow. Use `for i, sample in enumerate(ds)` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "# X, y = extract_filtered_mfcc_features(dataset)\n",
    "\n",
    "# Scale/ normalize features \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Balance dataset out / generate synthetic samples for under-represented classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Toazt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.69065008 0.64784575 0.65506685        nan 0.65362302        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'solver': 'sag', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV (GridSearchCV can take a long long time when not using average mfcc's )\n",
    "# Hypertuning Parameters\n",
    "param_distributions = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],  # Regularization strength\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'liblinear'],  \n",
    "    'penalty': ['l2', None],  # Regularization method\n",
    "}\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=1000, random_state=42, tol=1e-4, class_weight='balanced'),\n",
    "    param_distributions=param_distributions,\n",
    "    verbose = 2,  # Show logs as it runs\n",
    "    n_iter=6,  # Only sample 6 combinations\n",
    "    cv=3,  # Folds for cross validation\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "\n",
    "# Grid search \n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1.0, 10.0],  # Reduced from 4 to 3 values\n",
    "#     'solver': ['newton-cg', 'saga', 'sag'],  # Reduced from 4 to 2 solvers\n",
    "#     'penalty': ['l2']  # Reduced to just l2 penalty\n",
    "# }\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     LogisticRegression(max_iter=1000, random_state=42, tol=1e-4, class_weight='balanced'),\n",
    "#     param_grid,\n",
    "#     verbose=2,  # Show logs as it runs\n",
    "#     cv=3,  # Folds for cross validation\n",
    "#     n_jobs=-1  # Use all CPU cores\n",
    "# )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "print(\"Training model...\")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {search.best_params_}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Logistic Regression Accuracy: 0.6854\n",
      "\n",
      "Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.70      0.68      0.69       476\n",
      "          go       0.66      0.70      0.68       476\n",
      "        stop       0.74      0.70      0.72       476\n",
      "          up       0.64      0.66      0.65       476\n",
      "\n",
      "    accuracy                           0.69      1904\n",
      "   macro avg       0.69      0.69      0.69      1904\n",
      "weighted avg       0.69      0.69      0.69      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = search.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 68 is both random and grid so far with all mffc's, not average used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "d161be9a-3b35-4d3d-9d1d-a799bc34232f"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
